{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e7e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score, \n",
    "                           balanced_accuracy_score, f1_score, precision_score, recall_score)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Advanced ML libraries\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "    print(\"LightGBM not available. Install with: pip install lightgbm\")\n",
    "\n",
    "# Explainability\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "    print(\"SHAP not available. Install with: pip install shap\")\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"XGBoost available: {XGBOOST_AVAILABLE}\")\n",
    "print(f\"LightGBM available: {LIGHTGBM_AVAILABLE}\")\n",
    "print(f\"SHAP available: {SHAP_AVAILABLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a487e9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING PREPROCESSED DATA\n",
      "...Preprocessed data loaded successfully!!....\n",
      "Training set: (356396, 10)\n",
      "Validation set: (118799, 10)\n",
      "Test set: (118799, 10)\n",
      "\n",
      "Class distribution:\n",
      "Training set:\n",
      "loan_paid_back\n",
      "0     71700\n",
      "1    284696\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation set:\n",
      "loan_paid_back\n",
      "0    23900\n",
      "1    94899\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set:\n",
      "loan_paid_back\n",
      "0    23900\n",
      "1    94899\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed datasets\n",
    "print(\"LOADING PREPROCESSED DATA\")\n",
    " \n",
    "try:\n",
    "    # Load preprocessed datasets\n",
    "    X_train = pd.read_csv('X_train_scaled.csv')\n",
    "    X_val = pd.read_csv('X_val_scaled.csv')\n",
    "    X_test = pd.read_csv('X_test_scaled.csv')\n",
    "    \n",
    "    y_train = pd.read_csv('y_train.csv').squeeze()\n",
    "    y_val = pd.read_csv('y_val.csv').squeeze()\n",
    "    y_test = pd.read_csv('y_test.csv').squeeze()\n",
    "    ### The .squeeze() method removes dimensions of size 1, converting a DataFrame to a Series\n",
    "    ### The .squeeze() method is a clean, robust way to ensure your target variables are in the correct 1D format that sklearn expects, \n",
    "    ### preventing potential errors during model training and evaluation.\n",
    "    \n",
    "    # Load preprocessing objects\n",
    "    scaler = joblib.load('scaler.pkl')\n",
    "    \n",
    "    print(\"...Preprocessed data loaded successfully!!....\")\n",
    "    print(f\"Training set: {X_train.shape}\")\n",
    "    print(f\"Validation set: {X_val.shape}\")\n",
    "    print(f\"Test set: {X_test.shape}\")\n",
    "    \n",
    "    # Display class distribution\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(\"Training set:\")\n",
    "    print(y_train.value_counts().sort_index())\n",
    "    print(\"\\nValidation set:\")\n",
    "    print(y_val.value_counts().sort_index())\n",
    "    print(\"\\nTest set:\")\n",
    "    print(y_test.value_counts().sort_index())\n",
    "    \n",
    "        \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading preprocessed data: {e}\")\n",
    "    print(\"Please run the preprocessing notebook first to generate the required files.\")\n",
    "    print(\"Required files: X_train_scaled.csv, X_val_scaled.csv, X_test_scaled.csv\")\n",
    "    print(\"                y_train.csv, y_val.csv, y_test.csv\")\n",
    "    print(\"                scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9180af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score\n",
    ")\n",
    "from tqdm import tqdm  # optional, shows progress\n",
    "\n",
    "# ===================== FUNCTION TO TRAIN AND EVALUATE =====================\n",
    "def evaluate_model(model, model_name, X_train, y_train, X_val, y_val, X_test, y_test, compute_train=False):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation and test\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Probabilities for AUC\n",
    "    try:\n",
    "        y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    except AttributeError:\n",
    "        # For LinearSVC (no predict_proba)\n",
    "        y_val_proba = model.decision_function(X_val)\n",
    "        y_test_proba = model.decision_function(X_test)\n",
    "    \n",
    "    # Validation metrics\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    val_balanced_acc = balanced_accuracy_score(y_val, y_val_pred)\n",
    "    test_balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "    \n",
    "    val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "    test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "    \n",
    "    results = {\n",
    "        'model': model_name,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'val_balanced_acc': val_balanced_acc,\n",
    "        'test_balanced_acc': test_balanced_acc,\n",
    "        'val_f1': val_f1,\n",
    "        'test_f1': test_f1,\n",
    "        'val_auc': val_auc,\n",
    "        'test_auc': test_auc,\n",
    "        'time_sec': round(time.time() - start_time, 2)\n",
    "    }\n",
    "    \n",
    "    # Optional: compute train metrics\n",
    "    if compute_train:\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        try:\n",
    "            y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "        except AttributeError:\n",
    "            y_train_proba = model.decision_function(X_train)\n",
    "        \n",
    "        results.update({\n",
    "            'train_accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'train_balanced_acc': balanced_accuracy_score(y_train, y_train_pred),\n",
    "            'train_f1': f1_score(y_train, y_train_pred, average='macro'),\n",
    "            'train_auc': roc_auc_score(y_train, y_train_proba)\n",
    "        })\n",
    "    \n",
    "    print(f\"{model_name} completed in {results['time_sec']} sec | Val Acc: {val_accuracy:.3f}, Test Acc: {test_accuracy:.3f}\")\n",
    "    return results\n",
    "\n",
    "# ===================== MODEL LIST =====================\n",
    "models = [\n",
    "    ('SVM', SVC(kernel='rbf', class_weight='balanced')),  # remove probability=True for speed\n",
    "    # ('LinearSVC', LinearSVC(class_weight='balanced', max_iter=5000)), # optional fast SVM\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=234, class_weight='balanced', max_depth=10)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')),  # kd_tree faster\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=234)),\n",
    "    ('Naive Bayes', GaussianNB())\n",
    "]\n",
    "\n",
    "# ===================== RUN MODELS =====================\n",
    "all_results = []\n",
    "\n",
    "for name, model in tqdm(models, desc=\"Training Models\"):\n",
    "    result = evaluate_model(\n",
    "        model, name, \n",
    "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "        compute_train=False  # skip train metrics for speed\n",
    "    )\n",
    "    all_results.append(result)\n",
    "\n",
    "print(\"\\nAll models completed!\")\n",
    "\n",
    "# ===================== OPTIONAL: display results nicely =====================\n",
    "import pandas as pd\n",
    "df_results = pd.DataFrame(all_results)\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346a547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUPPORT VECTOR MACHINE (SVM) MODEL\n"
     ]
    }
   ],
   "source": [
    "# ===================== CONFUSION MATRIX FUNCTION =====================\n",
    "# def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "#     \"\"\"\n",
    "#     Display confusion matrix heatmap for classification models.\n",
    "#     \"\"\"\n",
    "#     cm = confusion_matrix(y_true, y_pred)\n",
    "#     plt.figure(figsize=(5, 4))\n",
    "#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "#                 xticklabels=['Pred: Slow', 'Pred: Fast'],\n",
    "#                 yticklabels=['Actual: Slow', 'Actual: Fast'])\n",
    "#     plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "#     plt.xlabel(\"Predicted Labels\")\n",
    "#     plt.ylabel(\"True Labels\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# Store all model results\n",
    "all_results = []\n",
    "\n",
    "# ===================== SVM =====================\n",
    "print(\"\\nSUPPORT VECTOR MACHINE (SVM) MODEL\")\n",
    "svm_model = SVC(\n",
    "kernel='rbf',\n",
    "probability=True,\n",
    "class_weight='balanced',\n",
    "random_state=234\n",
    ")\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svm_model.predict(X_train)\n",
    "y_val_pred = svm_model.predict(X_val)\n",
    "y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "# === AUC probabilities ===\n",
    "y_train_proba = svm_model.predict_proba(X_train)[:, 1]\n",
    "y_val_proba = svm_model.predict_proba(X_val)[:, 1]\n",
    "y_test_proba = svm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_balanced_acc = balanced_accuracy_score(y_train, y_train_pred)\n",
    "val_balanced_acc = balanced_accuracy_score(y_val, y_val_pred)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "# === AUC scores ===\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"SVM Performance:\")\n",
    "print(f\"Train - Acc: {train_accuracy:.3f}, BalAcc: {train_balanced_acc:.3f}, F1: {train_f1:.3f}, AUC: {train_auc:.3f}\")\n",
    "print(f\"Val - Acc: {val_accuracy:.3f}, BalAcc: {val_balanced_acc:.3f}, F1: {val_f1:.3f}. AUC: {val_auc:.3f}\")\n",
    "print(f\"Test - Acc: {test_accuracy:.3f}, BalAcc: {test_balanced_acc:.3f}, F1: {test_f1:.3f}, AUC: {test_auc:.3f}\")\n",
    "\n",
    "all_results.append({\n",
    "    'model': 'SVM',\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'val_accuracy': val_accuracy,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'train_balanced_acc': train_balanced_acc,\n",
    "    'val_balanced_acc': val_balanced_acc,\n",
    "    'test_balanced_acc': test_balanced_acc,\n",
    "    'train_f1': train_f1,\n",
    "    'val_f1': val_f1,\n",
    "    'test_f1': test_f1,\n",
    "    'train_auc': train_auc,\n",
    "    'val_auc': val_auc,\n",
    "    'test_auc': test_auc\n",
    "})\n",
    "\n",
    "\n",
    "# ===================== DECISION TREE =====================\n",
    "print(\"\\nDECISION TREE CLASSIFIER\")\n",
    "tree_model = DecisionTreeClassifier(\n",
    "    random_state=234,\n",
    "    class_weight='balanced',\n",
    "    max_depth=10\n",
    ")\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = tree_model.predict(X_train)\n",
    "y_val_pred = tree_model.predict(X_val)\n",
    "y_test_pred = tree_model.predict(X_test)\n",
    "\n",
    "# === AUC probabilities ===\n",
    "y_train_proba = tree_model.predict_proba(X_train)[:, 1]\n",
    "y_val_proba = tree_model.predict_proba(X_val)[:, 1]\n",
    "y_test_proba = tree_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_balanced_acc = balanced_accuracy_score(y_train, y_train_pred)\n",
    "val_balanced_acc = balanced_accuracy_score(y_val, y_val_pred)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "# === AUC scores ===\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"Decision Tree Performance:\")\n",
    "print(f\"Train - Acc: {train_accuracy:.3f}, BalAcc: {train_balanced_acc:.3f}, F1: {train_f1:.3f}, AUC: {train_auc:.3f}\")\n",
    "print(f\"Val - Acc: {val_accuracy:.3f}, BalAcc: {val_balanced_acc:.3f}, F1: {val_f1:.3f}, AUC: {val_auc:.3f}\")\n",
    "print(f\"Test - Acc: {test_accuracy:.3f}, BalAcc: {test_balanced_acc:.3f}, F1: {test_f1:.3f}, AUC: {test_auc:.3f}\")\n",
    "\n",
    "all_results.append({\n",
    "    'model': 'Decision Tree',\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'val_accuracy': val_accuracy,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'train_balanced_acc': train_balanced_acc,\n",
    "    'val_balanced_acc': val_balanced_acc,\n",
    "    'test_balanced_acc': test_balanced_acc,\n",
    "    'train_f1': train_f1,\n",
    "    'val_f1': val_f1,\n",
    "    'test_f1': test_f1,\n",
    "    'train_auc': train_auc,\n",
    "    'val_auc': val_auc,\n",
    "    'test_auc': test_auc\n",
    "})\n",
    "\n",
    "\n",
    "# ===================== KNN =====================\n",
    "print(\"\\nK-NEAREST NEIGHBORS (KNN)\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = knn_model.predict(X_train)\n",
    "y_val_pred = knn_model.predict(X_val)\n",
    "y_test_pred = knn_model.predict(X_test)\n",
    "\n",
    "# === AUC probabilities ===\n",
    "y_train_proba = knn_model.predict_proba(X_train)[:, 1]\n",
    "y_val_proba = knn_model.predict_proba(X_val)[:, 1]\n",
    "y_test_proba = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_balanced_acc = balanced_accuracy_score(y_train, y_train_pred)\n",
    "val_balanced_acc = balanced_accuracy_score(y_val, y_val_pred)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "# === AUC scores ===\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"KNN Performance:\")\n",
    "print(f\"Train - Acc: {train_accuracy:.3f}, BalAcc: {train_balanced_acc:.3f}, F1: {train_f1:.3f}, AUC: {train_auc:.3f}\")\n",
    "print(f\"Val - Acc: {val_accuracy:.3f}, BalAcc: {val_balanced_acc:.3f}, F1: {val_f1:.3f}, AUC: {val_auc:.3f}\")\n",
    "print(f\"Test - Acc: {test_accuracy:.3f}, BalAcc: {test_balanced_acc:.3f}, F1: {test_f1:.3f}, AUC: {test_auc:.3f}\")\n",
    "\n",
    "all_results.append({\n",
    "    'model': 'KNN',\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'val_accuracy': val_accuracy,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'train_balanced_acc': train_balanced_acc,\n",
    "    'val_balanced_acc': val_balanced_acc,\n",
    "    'test_balanced_acc': test_balanced_acc,\n",
    "    'train_f1': train_f1,\n",
    "    'val_f1': val_f1,\n",
    "    'test_f1': test_f1,\n",
    "    'train_auc': train_auc,\n",
    "    'val_auc': val_auc,\n",
    "    'test_auc': test_auc\n",
    "})\n",
    "\n",
    "\n",
    "# ===================== GRADIENT BOOSTING =====================\n",
    "print(\"\\nGRADIENT BOOSTING CLASSIFIER\")\n",
    "gb_model = GradientBoostingClassifier(random_state=234)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = gb_model.predict(X_train)\n",
    "y_val_pred = gb_model.predict(X_val)\n",
    "y_test_pred = gb_model.predict(X_test)\n",
    "\n",
    "# === AUC probabilities ===\n",
    "y_train_proba = gb_model.predict_proba(X_train)[:, 1]\n",
    "y_val_proba = gb_model.predict_proba(X_val)[:, 1]\n",
    "y_test_proba = gb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_balanced_acc = balanced_accuracy_score(y_train, y_train_pred)\n",
    "val_balanced_acc = balanced_accuracy_score(y_val, y_val_pred)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "# === AUC scores ===\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"Gradient Boosting Performance:\")\n",
    "print(f\"Train - Acc: {train_accuracy:.3f}, BalAcc: {train_balanced_acc:.3f}, F1: {train_f1:.3f}, AUC: {train_auc:.3f}\")\n",
    "print(f\"Val - Acc: {val_accuracy:.3f}, BalAcc: {val_balanced_acc:.3f}, F1: {val_f1:.3f}, AUC: {val_auc:.3f}\")\n",
    "print(f\"Test - Acc: {test_accuracy:.3f}, BalAcc: {test_balanced_acc:.3f}, F1: {test_f1:.3f}, AUC: {test_auc:.3f}\")\n",
    "\n",
    "all_results.append({\n",
    "    'model': 'Gradient Boosting',\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'val_accuracy': val_accuracy,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'train_balanced_acc': train_balanced_acc,\n",
    "    'val_balanced_acc': val_balanced_acc,\n",
    "    'test_balanced_acc': test_balanced_acc,\n",
    "    'train_f1': train_f1,\n",
    "    'val_f1': val_f1,\n",
    "    'test_f1': test_f1,\n",
    "    'train_auc': train_auc,\n",
    "    'val_auc': val_auc,\n",
    "    'test_auc': test_auc\n",
    "})\n",
    "\n",
    "\n",
    "# ===================== NAIVE BAYES =====================\n",
    "print(\"\\nGAUSSIAN NAIVE BAYES\")\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = nb_model.predict(X_train)\n",
    "y_val_pred = nb_model.predict(X_val)\n",
    "y_test_pred = nb_model.predict(X_test)\n",
    "\n",
    "# === AUC probabilities ===\n",
    "y_train_proba = nb_model.predict_proba(X_train)[:, 1]\n",
    "y_val_proba = nb_model.predict_proba(X_val)[:, 1]\n",
    "y_test_proba = nb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_balanced_acc = balanced_accuracy_score(y_train, y_train_pred)\n",
    "val_balanced_acc = balanced_accuracy_score(y_val, y_val_pred)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "# === AUC scores ===\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"Naive Bayes Performance:\")\n",
    "print(f\"Train - Acc: {train_accuracy:.3f}, BalAcc: {train_balanced_acc:.3f}, F1: {train_f1:.3f}, AUC: {train_auc:.3f}\")\n",
    "print(f\"Val - Acc: {val_accuracy:.3f}, BalAcc: {val_balanced_acc:.3f}, F1: {val_f1:.3f}, AUC: {val_auc:.3f}\")\n",
    "print(f\"Test - Acc: {test_accuracy:.3f}, BalAcc: {test_balanced_acc:.3f}, F1: {test_f1:.3f}, AUC: {test_auc:.3f}\")\n",
    "\n",
    "all_results.append({\n",
    "    'model': 'Naive Bayes',\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'val_accuracy': val_accuracy,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'train_balanced_acc': train_balanced_acc,\n",
    "    'val_balanced_acc': val_balanced_acc,\n",
    "    'test_balanced_acc': test_balanced_acc,\n",
    "    'train_f1': train_f1,\n",
    "    'val_f1': val_f1,\n",
    "    'test_f1': test_f1,\n",
    "    'train_auc': train_auc,\n",
    "    'val_auc': val_auc,\n",
    "    'test_auc': test_auc\n",
    "})\n",
    "\n",
    "print(\"\\nAll additional models completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(y_test, y_test_pred, \"SVM\")\n",
    "# plot_confusion_matrix(y_test, y_test_pred, \"Decision Tree\")\n",
    "# plot_confusion_matrix(y_test, y_test_pred, \"KNN\")\n",
    "# plot_confusion_matrix(y_test, y_test_pred, \"Gradient Boosting\")\n",
    "# plot_confusion_matrix(y_test, y_test_pred, \"Naive Bayes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== CONFUSION MATRIX FUNCTION =====================\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Display confusion matrix heatmap for classification models.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Pred: Slow', 'Pred: Fast'],\n",
    "                yticklabels=['Actual: Slow', 'Actual: Fast'])\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ===================== BASELINE LOGISTIC REGRESSION =====================\n",
    "print(\"BASELINE LOGISTIC REGRESSION MODEL\")\n",
    "\n",
    "baseline_model = LogisticRegression(\n",
    "    random_state=234,\n",
    "    max_iter=100,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = baseline_model.predict(X_train)\n",
    "y_val_pred = baseline_model.predict(X_val)\n",
    "y_test_pred = baseline_model.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_bal_acc = balanced_accuracy_score(y_train, y_train_pred)\n",
    "val_bal_acc = balanced_accuracy_score(y_val, y_val_pred)\n",
    "test_bal_acc = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "print(f\"Training - Accuracy: {train_accuracy:.3f}, Balanced Acc: {train_bal_acc:.3f}, F1: {train_f1:.3f}, AUC: {train_auc:.3f}\")\n",
    "print(f\"Validation - Accuracy: {val_accuracy:.3f}, Balanced Acc: {val_bal_acc:.3f}, F1: {val_f1:.3f}, AUC: {val_auc:.3f}\")\n",
    "print(f\"Test - Accuracy: {test_accuracy:.3f}, Balanced Acc: {test_bal_acc:.3f}, F1: {test_f1:.3f}, AUC: {test_auc:.3f}\")\n",
    "\n",
    "plot_confusion_matrix(y_test, y_test_pred, \"Logistic Regression\")\n",
    "\n",
    "\n",
    "# ===================== SVM =====================\n",
    "print(\"\\nSUPPORT VECTOR MACHINE (SVM) MODEL\")\n",
    "svm_model = SVC(kernel='rbf', probability=True, class_weight='balanced', random_state=234)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {accuracy_score(y_test, y_test_pred):.3f}, F1: {f1_score(y_test, y_test_pred, average='macro'):.3f}\")\n",
    "plot_confusion_matrix(y_test, y_test_pred, \"SVM\")\n",
    "\n",
    "\n",
    "# ===================== DECISION TREE =====================\n",
    "print(\"\\nDECISION TREE CLASSIFIER\")\n",
    "tree_model = DecisionTreeClassifier(random_state=234, class_weight='balanced', max_depth=10)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = tree_model.predict(X_test)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_score(y_test, y_test_pred):.3f}, F1: {f1_score(y_test, y_test_pred, average='macro'):.3f}\")\n",
    "plot_confusion_matrix(y_test, y_test_pred, \"Decision Tree\")\n",
    "\n",
    "\n",
    "# ===================== KNN =====================\n",
    "print(\"\\nK-NEAREST NEIGHBORS (KNN)\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = knn_model.predict(X_test)\n",
    "\n",
    "print(f\"KNN Test Accuracy: {accuracy_score(y_test, y_test_pred):.3f}, F1: {f1_score(y_test, y_test_pred, average='macro'):.3f}\")\n",
    "plot_confusion_matrix(y_test, y_test_pred, \"KNN\")\n",
    "\n",
    "\n",
    "# ===================== RANDOM FOREST =====================\n",
    "print(\"\\nRANDOM FOREST CLASSIFIER\")\n",
    "rf_model = RandomForestClassifier(random_state=234, class_weight='balanced', n_estimators=150)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_score(y_test, y_test_pred):.3f}, F1: {f1_score(y_test, y_test_pred, average='macro'):.3f}\")\n",
    "plot_confusion_matrix(y_test, y_test_pred, \"Random Forest\")\n",
    "\n",
    "\n",
    "# ===================== XGBOOST =====================\n",
    "print(\"\\nXGBOOST CLASSIFIER\")\n",
    "xgb_model = XGBClassifier(random_state=234, eval_metric='logloss', use_label_encoder=False)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "\n",
    "print(f\"XGBoost Test Accuracy: {accuracy_score(y_test, y_test_pred):.3f}, F1: {f1_score(y_test, y_test_pred, average='macro'):.3f}\")\n",
    "plot_confusion_matrix(y_test, y_test_pred, \"XGBoost\")\n",
    "\n",
    "\n",
    "# ===================== GRADIENT BOOSTING =====================\n",
    "print(\"\\nGRADIENT BOOSTING CLASSIFIER\")\n",
    "gb_model = GradientBoostingClassifier(random_state=234)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = gb_model.predict(X_test)\n",
    "\n",
    "print(f\"Gradient Boosting Test Accuracy: {accuracy_score(y_test, y_test_pred):.3f}, F1: {f1_score(y_test, y_test_pred, average='macro'):.3f}\")\n",
    "plot_confusion_matrix(y_test, y_test_pred, \"Gradient Boosting\")\n",
    "\n",
    "\n",
    "# ===================== NAIVE BAYES =====================\n",
    "print(\"\\nGAUSSIAN NAIVE BAYES\")\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = nb_model.predict(X_test)\n",
    "\n",
    "print(f\"Naive Bayes Test Accuracy: {accuracy_score(y_test, y_test_pred):.3f}, F1: {f1_score(y_test, y_test_pred, average='macro'):.3f}\")\n",
    "plot_confusion_matrix(y_test, y_test_pred, \"Naive Bayes\")\n",
    "\n",
    "\n",
    "print(\"\\nAll models trained, evaluated, and confusion matrices displayed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5388cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Compare all models\n",
    "# ==============================\n",
    "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "# Create a list of models and their objects\n",
    "models = {\n",
    "    \"Logistic Regression\": baseline_model,\n",
    "    \"SVM\": svm_model,\n",
    "    \"Decision Tree\": tree_model,\n",
    "    \"KNN\": knn_model,\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"XGBoost\": xgb_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Store metrics for comparison\n",
    "model_comparison = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # ---- AUC ----\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "    except:\n",
    "        auc = None  # Some models (like SVM without probability=True) may fail\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    model_comparison.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'Balanced Accuracy': bal_acc,\n",
    "        'F1 Score': f1,\n",
    "        'AUC': auc\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easy comparison\n",
    "comparison_df = pd.DataFrame(model_comparison).sort_values(by='F1 Score', ascending=False)\n",
    "print(\"\\nModel Performance Comparison (Test Set):\")\n",
    "print(comparison_df)\n",
    "\n",
    "# ==============================\n",
    "# Select Best Model\n",
    "# ==============================\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "y_test_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(f\"\\nBest Model Selected: {best_model_name}\")\n",
    "print(f\"Test F1 Score: {comparison_df.iloc[0]['F1 Score']:.3f}\")\n",
    "\n",
    "# ==============================\n",
    "# Detailed Evaluation of Best Model\n",
    "# ==============================\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(f\"\\nDetailed Classification Report for {best_model_name}:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_test_pred_best))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred_best)\n",
    "print(f\"\\nConfusion Matrix for {best_model_name}:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=sorted(y_test.unique()),\n",
    "            yticklabels=sorted(y_test.unique()))\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "print(f\"\\nPer-class Accuracy for {best_model_name}:\")\n",
    "for cls in sorted(y_test.unique()):\n",
    "    mask = y_test == cls\n",
    "    class_acc = accuracy_score(y_test[mask], y_test_pred_best[mask])\n",
    "    print(f\"Class {cls}: {class_acc:.3f} ({mask.sum()} samples)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# ==============================\n",
    "# Compare all models (already trained)\n",
    "# ==============================\n",
    "models = {\n",
    "    \"Logistic Regression\": baseline_model,\n",
    "    \"SVM\": svm_model,\n",
    "    \"Decision Tree\": tree_model,\n",
    "    \"KNN\": knn_model,\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"XGBoost\": xgb_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Collect test metrics\n",
    "model_comparison = []\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "    except:\n",
    "        auc = None\n",
    "\n",
    "    model_comparison.append({\n",
    "        'Model': name,\n",
    "        'F1 Score': f1,\n",
    "        'AUC': auc\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(model_comparison).sort_values(by='F1 Score', ascending=False)\n",
    "print(\"\\nModel Performance Comparison (Test F1):\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Select best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nBest model selected: {best_model_name} with F1 Score: {comparison_df.iloc[0]['F1 Score']:.3f}\")\n",
    "\n",
    "# ==============================\n",
    "# RandomizedSearchCV on best model\n",
    "# ==============================\n",
    "# Define hyperparameter grids for supported models\n",
    "param_grids = {\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "        'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 150, 200],\n",
    "        'max_depth': [None, 5, 10, 15],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'class_weight': ['balanced', 'balanced_subsample']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100, 150, 200],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 150, 200],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Only tune models that support hyperparameters\n",
    "if best_model_name in param_grids:\n",
    "    print(f\"\\nRunning RandomizedSearchCV for {best_model_name}...\")\n",
    "    rs = RandomizedSearchCV(\n",
    "        estimator=best_model,\n",
    "        param_distributions=param_grids[best_model_name],\n",
    "        n_iter=20,\n",
    "        scoring='f1_macro',\n",
    "        cv=5,\n",
    "        verbose=2,\n",
    "        random_state=234,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rs.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = rs.best_estimator_\n",
    "    print(f\"Best hyperparameters for {best_model_name}: {rs.best_params_}\")\n",
    "    print(f\"Best CV F1-score: {rs.best_score_:.3f}\")\n",
    "else:\n",
    "    print(f\"{best_model_name} does not have hyperparameters to tune with RandomizedSearchCV.\")\n",
    "\n",
    "# ==============================\n",
    "# Evaluate Tuned Best Model\n",
    "# ==============================\n",
    "y_test_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# ---- AUC calculation ----\n",
    "try:\n",
    "    y_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "    auc_best = roc_auc_score(y_test, y_proba_best)\n",
    "except:\n",
    "    auc_best = None\n",
    "\n",
    "print(f\"\\nDetailed Evaluation of Tuned Best Model: {best_model_name}\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_test_pred_best))\n",
    "print(f\"AUC: {auc_best:.3f}\" if auc_best is not None else \"AUC: Not available for this model\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred_best)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=sorted(y_test.unique()),\n",
    "            yticklabels=sorted(y_test.unique()))\n",
    "plt.title(f'Confusion Matrix - Tuned {best_model_name}')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# ===================== SAVE BEST MODEL AND RESULTS =====================\n",
    "\n",
    "print(\"\\nSAVING BEST MODEL AND RESULTS\")\n",
    "\n",
    "# Example: Suppose you already determined best_model_name and best_model\n",
    "# (e.g. best_model_name = 'XGBoost'; best_model = xgb_model)\n",
    "\n",
    "# Create a results folder\n",
    "os.makedirs(\"model_results\", exist_ok=True)\n",
    "\n",
    "# Save the model using joblib\n",
    "model_path = f\"model_results/best_model_{best_model_name.replace(' ', '_')}.pkl\"\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "print(f\"Best model '{best_model_name}' saved to: {model_path}\")\n",
    "\n",
    "# Calculate AUC if supported\n",
    "try:\n",
    "    y_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "    auc_score = roc_auc_score(y_test, y_proba_best)\n",
    "except:\n",
    "    auc_score = None\n",
    "\n",
    "# Collect performance results\n",
    "best_model_results = {\n",
    "    \"model_name\": best_model_name,\n",
    "    \"test_accuracy\": accuracy_score(y_test, y_test_pred_best),\n",
    "    \"test_balanced_accuracy\": balanced_accuracy_score(y_test, y_test_pred_best),\n",
    "    \"test_f1_macro\": f1_score(y_test, y_test_pred_best, average='macro'),\n",
    "    \"test_auc\": auc_score,  # Added AUC here\n",
    "    \"confusion_matrix\": confusion_matrix(y_test, y_test_pred_best).tolist(),  # convert to list for JSON\n",
    "}\n",
    "\n",
    "# Save results to a JSON file\n",
    "results_path = f\"model_results/{best_model_name.replace(' ', '_')}_results.json\"\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(best_model_results, f, indent=4)\n",
    "\n",
    "print(f\"Model evaluation metrics saved to: {results_path}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nBest Model Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(json.dumps(best_model_results, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
